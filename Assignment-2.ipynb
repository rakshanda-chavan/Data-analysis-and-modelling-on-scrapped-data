{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP41680 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Data Collection\n",
    "\n",
    "We use the provided web link to extract data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import all the packages required\n",
    "#pip install beautifulsoup4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLBase = \"http://mlg.ucd.ie/modules/COMP41680/assignment2/\"  ##The baseUrl remains constant for all the pages.\n",
    "URL = URLBase + \"index.html\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opened the page on web browser and with the help of inspect element tool found the id of the body which contains the page data.\n",
    "results = soup.find(id='all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"all\">\n",
      " <div class=\"list-group\">\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-jan-001.html\">\n",
      "   January 2020  [1522]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-feb-001.html\">\n",
      "   February 2020  [1492]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-mar-001.html\">\n",
      "   March 2020  [1395]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-apr-001.html\">\n",
      "   April 2020  [1209]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-may-001.html\">\n",
      "   May 2020  [1315]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-jun-001.html\">\n",
      "   June 2020  [1376]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-jul-001.html\">\n",
      "   July 2020  [1358]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-aug-001.html\">\n",
      "   August 2020  [1254]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-sep-001.html\">\n",
      "   September 2020  [1347]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-oct-001.html\">\n",
      "   October 2020  [1395]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-nov-001.html\">\n",
      "   November 2020  [1343]\n",
      "  </a>\n",
      "  <a class=\"list-group-item list-group-item-action\" href=\"month-dec-001.html\">\n",
      "   December 2020  [1220]\n",
      "  </a>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##To understand the structure of the web pages containing the required data we print it using prettify() which formats the html for better understanding.\n",
    "print(results.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['month-jan-001.html', 'month-feb-001.html', 'month-mar-001.html', 'month-apr-001.html', 'month-may-001.html', 'month-jun-001.html', 'month-jul-001.html', 'month-aug-001.html', 'month-sep-001.html', 'month-oct-001.html', 'month-nov-001.html', 'month-dec-001.html']\n"
     ]
    }
   ],
   "source": [
    "#Above we could see hrefs which are used to navigate to other pages for specific months.\n",
    "#So we scrap the hrefs for all the months and save them in the list which we can append to the baseURL to navigate to other pages.\n",
    "\n",
    "hrefList = []\n",
    "href_elements = soup.find_all('a', {'class':'list-group-item list-group-item-action'})\n",
    "for href_element in href_elements:\n",
    "    text = href_element['href'] \n",
    "    hrefList.append(text)\n",
    "\n",
    "print(hrefList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have created a dataframe having 3 columns to save the title, story snippet and category of the news that we scrap from the urls.\n",
    "columns = [\"title\",\"snippet\",\"category\"]\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for href in hrefList:\n",
    "    page = requests.get(URLBase+href) #the basseURL and URL for every month to navigate to that specific month's page\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    pages = soup.find_all('h4', {'class':'results'})\n",
    "\n",
    "    #Every month had around 1500 records of news which were divided into different pages to view. So we scrap the number of pages\n",
    "    #present in every month to get all the data from all pages.\n",
    "    pageNo = pages[0].get_text() \n",
    "    pageNo = pageNo[-2:]\n",
    "\n",
    "    pages = [href]\n",
    "\n",
    "    #we loop through all the page numbers as they all contain different URL's.\n",
    "    x = '001'\n",
    "    for z in range(int(pageNo)-1):\n",
    "        x = str(int(x) + 1).zfill(len(x))\n",
    "        if len(x) == 3:\n",
    "            x = x[1:]\n",
    "        pages.append(href[0:11] + x + href[13:18])\n",
    "    \n",
    "    #Once we have all the URL's gathered for all the pages for a month we iterate through all the pages to collect the data.\n",
    "    for page in pages:\n",
    "        page = requests.get(URLBase+page)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        articles = soup.find_all('div', {'class':'article'})\n",
    "\n",
    "        for ar in articles:\n",
    "            title = ar.find(\"h5\").get_text() #Gets the title of the news\n",
    "            title = title.lstrip('0123456789.- ') #Used to strip the number in front of the news title.\n",
    "            target = ar.find_all('p', {'class':'metadata'})\n",
    "            category = target[1].get_text()\n",
    "            category = category[9:]\n",
    "            category = category.strip().replace('s/+',\"\") #Gets the category of the news article\n",
    "            if category == 'Music' or category == 'Books' or category == 'Film': #Condition to only save the articles belonging to either music, books or film category.\n",
    "                df.loc[i] = [title, ar.find('p',{'class':'snippet'}).get_text(), category]\n",
    "                i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be honest. You're not going to read all those...</td>\n",
       "      <td>Every year, about this time, my Instagram feed...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mariah Carey's Twitter account hacked on New ...</td>\n",
       "      <td>Mariah Carey’s Twitter account appeared to hav...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Providence Lost by Paul Lay review – the rise...</td>\n",
       "      <td>The only public execution of a British head of...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>War epics, airmen and young Sopranos: essenti...</td>\n",
       "      <td>1917 An epic of Lean-ian proportions is delive...</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'I'm on the hunt for humour and hope': what w...</td>\n",
       "      <td>Matt Haig I have been very dark and gloomy wit...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>Banging toons: why bands such as Bis are maki...</td>\n",
       "      <td>An architect cranks a lever, and suddenly Mr S...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>Little Scratch by Rebecca Watson review - a d...</td>\n",
       "      <td>Rebecca Watson’s debut novel started life as a...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>'All that mattered was survival': the songs t...</td>\n",
       "      <td>Isaac Hayes – Going in Circles When it came to...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>‘It took its toll’: the terrible legacy of Ma...</td>\n",
       "      <td>Summary: As a child in 1960s east Harlem, docu...</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>MF Doom, iconic masked hip-hop MC, dies aged 49</td>\n",
       "      <td>MF Doom, one of US hip-hop’s most distinctive ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0      Be honest. You're not going to read all those...   \n",
       "1      Mariah Carey's Twitter account hacked on New ...   \n",
       "2      Providence Lost by Paul Lay review – the rise...   \n",
       "3      War epics, airmen and young Sopranos: essenti...   \n",
       "4      'I'm on the hunt for humour and hope': what w...   \n",
       "...                                                 ...   \n",
       "5384   Banging toons: why bands such as Bis are maki...   \n",
       "5385   Little Scratch by Rebecca Watson review - a d...   \n",
       "5386   'All that mattered was survival': the songs t...   \n",
       "5387   ‘It took its toll’: the terrible legacy of Ma...   \n",
       "5388    MF Doom, iconic masked hip-hop MC, dies aged 49   \n",
       "\n",
       "                                                snippet category  \n",
       "0     Every year, about this time, my Instagram feed...    Books  \n",
       "1     Mariah Carey’s Twitter account appeared to hav...    Music  \n",
       "2     The only public execution of a British head of...    Books  \n",
       "3     1917 An epic of Lean-ian proportions is delive...     Film  \n",
       "4     Matt Haig I have been very dark and gloomy wit...    Books  \n",
       "...                                                 ...      ...  \n",
       "5384  An architect cranks a lever, and suddenly Mr S...    Music  \n",
       "5385  Rebecca Watson’s debut novel started life as a...    Books  \n",
       "5386  Isaac Hayes – Going in Circles When it came to...    Music  \n",
       "5387  Summary: As a child in 1960s east Harlem, docu...     Film  \n",
       "5388  MF Doom, one of US hip-hop’s most distinctive ...    Music  \n",
       "\n",
       "[5389 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have collected all the required data and stored it in a dataframe as it is easy to carry out operations on it.\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial observations\n",
    "* Here we can see that the dataset contains an approximately equal portion of each class. This means our dataset is balanced so we won’t perform any undersampling or oversampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Books    1821\n",
       "Music    1797\n",
       "Film     1771\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The only public execution of a British head of state occurred 371 years ago outside the Banqueting House in Whitehall on 30 January 1649. It was a rad …'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2]['snippet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text cleaning and preparation\n",
    "### 1.1. Special character cleaning\n",
    "We can see the following special characters:\n",
    "\n",
    "\\r\n",
    "\\n\n",
    "\\ before possessive pronouns \n",
    "\\ before possessive pronouns 2 \n",
    "\" when quoting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snippet'] = df['snippet'].str.replace(\"\\r\", \" \")\n",
    "df['snippet'] = df['snippet'].str.replace(\"\\n\", \" \")\n",
    "df['snippet'] = df['snippet'].str.replace(\"    \", \" \")\n",
    "# \"/' when quoting text\n",
    "df['snippet'] = df['snippet'].str.replace('\"', '')\n",
    "df['snippet'] = df['snippet'].str.replace(\"'\", \"\")\n",
    "\n",
    "\n",
    "df['title'] = df['title'].str.replace(\"\\r\", \" \")\n",
    "df['title'] = df['title'].str.replace(\"\\n\", \" \")\n",
    "df['title'] = df['title'].str.replace(\"    \", \" \")\n",
    "# \"/' when quoting text\n",
    "df['title'] = df['title'].str.replace('\"', '')\n",
    "df['title'] = df['title'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Upcase/downcase¶\n",
    "We'll downcase the texts because we want, for example, Whitehall and whitehall to be the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower-casing the text\n",
    "df['title'] = df['title'].str.lower()\n",
    "\n",
    "df['snippet'] = df['snippet'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Punctuation signs¶\n",
    "Punctuation signs won't have any predicting power, so we'll just get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['title'] = df['title'].str.replace(punct_sign, '')\n",
    "    df['snippet'] = df['snippet'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Stemming and Lemmatization¶\n",
    "Since stemming can produce output words that don't exist, we'll only use a lemmatization process. Lemmatization takes into consideration the morphological analysis of the words and returns words that do exist, so it will be more useful for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to lemmatize, we have to iterate through every word\n",
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['snippet']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "    \n",
    "nrows = len(df)\n",
    "lemmatized_text_list_title = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['title']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list_title.append(lemmatized_text)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snippet'] = lemmatized_text_list\n",
    "df['title'] = lemmatized_text_list_title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Although lemmatization doesn't work perfectly in all cases, it can be useful.\n",
    "<br>\n",
    "### 1.5. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\raksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['snippet'] = df['snippet']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['snippet'] = df['snippet'].str.replace(regex_stopword, '')\n",
    "    df['title'] = df['title'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honest youre  go  read   book   holiday</td>\n",
       "      <td>every year   time  instagram fee fill   pictur...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0    honest youre  go  read   book   holiday     \n",
       "\n",
       "                                             snippet category  \n",
       "0  every year   time  instagram fee fill   pictur...    Books  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Binary Text Classification\n",
    "\n",
    "For binary classification, we classify data into one of two binary groups - these are usually represented as 0's and 1's in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [document, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create a new dataframe of data for Binary classification of the news articles.\n",
    "BCcolumns = [\"document\",\"category\"]\n",
    "BFdf = pd.DataFrame(columns=BCcolumns)\n",
    "MFdf = pd.DataFrame(columns=BCcolumns)\n",
    "BMdf = pd.DataFrame(columns=BCcolumns)\n",
    "BFdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honest youre  go  read   book   holiday  eve...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mariah careys twitter account hack  new years...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>providence lose  paul lay review –  rise  fal...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im   hunt  humour  hope   author  read  2020m...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diary   murderer  kim young-ha review – dark ...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>humaning  nice idea  ridiculous corporate buz...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>banging toons  band   bis  make soundtracks  ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>little scratch  rebecca watson review -  dari...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>matter  survival  songs  get us  2020isaac ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>mf doom iconic mask hip-hop mc die age 49mf d...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3618 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document category\n",
       "0       honest youre  go  read   book   holiday  eve...    Books\n",
       "1      mariah careys twitter account hack  new years...    Music\n",
       "2      providence lose  paul lay review –  rise  fal...    Books\n",
       "3      im   hunt  humour  hope   author  read  2020m...    Books\n",
       "4      diary   murderer  kim young-ha review – dark ...    Books\n",
       "...                                                 ...      ...\n",
       "3613   humaning  nice idea  ridiculous corporate buz...    Books\n",
       "3614   banging toons  band   bis  make soundtracks  ...    Music\n",
       "3615   little scratch  rebecca watson review -  dari...    Books\n",
       "3616     matter  survival  songs  get us  2020isaac ...    Music\n",
       "3617   mf doom iconic mask hip-hop mc die age 49mf d...    Music\n",
       "\n",
       "[3618 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the main dataframe we have selected 2 categories of data i.e. Books and Film \n",
    "r = 0\n",
    "for index, row in df.iterrows():\n",
    "    if row['category'] == 'Books' or row['category'] == 'Film':\n",
    "        BFdf.loc[r] = [row['title'] + row['snippet'] , row['category']] #saved the title and snippet as one document.\n",
    "        r += 1\n",
    "BFdf\n",
    "\n",
    "r = 0\n",
    "for index, row in df.iterrows():\n",
    "    if row['category'] == 'Music' or row['category'] == 'Film':\n",
    "        MFdf.loc[r] = [row['title'] + row['snippet'] , row['category']] #saved the title and snippet as one document.\n",
    "        r += 1\n",
    "MFdf\n",
    "\n",
    "r = 0\n",
    "for index, row in df.iterrows():\n",
    "    if row['category'] == 'Music' or row['category'] == 'Books':\n",
    "        BMdf.loc[r] = [row['title'] + row['snippet'] , row['category']] #saved the title and snippet as one document.\n",
    "        r += 1\n",
    "BMdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have created dictionaries with category names which will be grouped together for binary classification.\n",
    "BF_category_codes = {\n",
    "    'Books': 0,\n",
    "    'Film': 1\n",
    "}\n",
    "MF_category_codes = {\n",
    "    'Music': 0,\n",
    "    'Film': 1\n",
    "}\n",
    "BM_category_codes = {\n",
    "    'Books': 0,\n",
    "    'Music': 1\n",
    "}\n",
    "# Category mapping\n",
    "BFdf['Category_Code'] = BFdf['category']\n",
    "BFdf = BFdf.replace({'Category_Code':BF_category_codes})\n",
    "\n",
    "MFdf['Category_Code'] = MFdf['category']\n",
    "MFdf = MFdf.replace({'Category_Code':MF_category_codes})\n",
    "\n",
    "BMdf['Category_Code'] = BMdf['category']\n",
    "BMdf = BMdf.replace({'Category_Code':BM_category_codes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split \n",
    "We'll set apart a test set to prove the quality of our models. We'll choose a test set size of 15% of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train-test split for Books and Film category from the dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(BFdf['document'], \n",
    "                                                    BFdf['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll use TF-IDF Vectors as features. \n",
    "\n",
    "We have to define the following parameters:\n",
    "\n",
    "ngram_range: We want to consider both unigrams and bigrams.<br>\n",
    "max_df: When building the dataset ignore terms that have a document frequency strictly higher than the given threshold.<br>\n",
    "min_df: When building the dataset ignore terms that have a document frequency strictly lower than the given threshold.<br>\n",
    "max_features: If not None, build a dataset that only consider the top max_features ordered by term frequency across the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter selection\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To transform the word sequences into numerical features we're using TF-IDF vectorization.\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, a combination of two metrics - term frequency(TF) and inverse document frequency(IDF), and the idea is to weigh down the frequent terms while scaling up the rare or less frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3053, 300)\n",
      "(539, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different combinations of parameter selection result in different accuracy of models.\n",
    "We have fitted and then transformed the training set, but we have only transformed the test set.\n",
    "<br>\n",
    "<br>\n",
    "We'll try multiple machine learning classification models in order to find which one performs best on our data. We will try with the following models:\n",
    "\n",
    "* K Nearest Neighbors<br>\n",
    "* Multinomial Naive Bayes<br>\n",
    "* Support Vector Machine<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "knnc_0 =KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "print('Parameters:\\n')\n",
    "print(knnc_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data and then get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnc_0.fit(features_train, labels_train)\n",
    "\n",
    "knnc_pred = knnc_0.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "We will use the below metrics for the evaluation of our models.\n",
    "\n",
    "* Accuracy: the accuracy metric measures the ratio of correct predictions over the total number of predictions.\n",
    "* Precision: precision is used to measure the positive preductions that are correctly predicted from the total predictions in a positive class.\n",
    "* Recall: recall is used to measure the fraction of positive pridictions that are correctly classified.\n",
    "* F1-Score: this metric represents the harmonic mean between recall and precision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.872911889944317\n",
      "The test accuracy is: \n",
      "0.7217068645640075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, knnc_0.predict(features_train)))\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, knnc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68       269\n",
      "           1       0.68      0.84      0.75       270\n",
      "\n",
      "    accuracy                           0.72       539\n",
      "   macro avg       0.73      0.72      0.72       539\n",
      "weighted avg       0.73      0.72      0.72       539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,knnc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aux_df = BFdf[['category', 'Category_Code']].drop_duplicates().sort_values('Category_Code')\n",
    "conf_matrix = confusion_matrix(labels_test, knnc_pred)\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=aux_df['category'].values, \n",
    "            yticklabels=aux_df['category'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc = MultinomialNB()\n",
    "mnbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc_pred = mnbc.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.8978054372748117\n",
      "The test accuracy is: \n",
      "0.8664192949907236\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, mnbc.predict(features_train)))\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, mnbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       269\n",
      "           1       0.89      0.84      0.86       270\n",
      "\n",
      "    accuracy                           0.87       539\n",
      "   macro avg       0.87      0.87      0.87       539\n",
      "weighted avg       0.87      0.87      0.87       539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,mnbc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aux_df = BFdf[['category', 'Category_Code']].drop_duplicates().sort_values('Category_Code')\n",
    "conf_matrix = confusion_matrix(labels_test, mnbc_pred)\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=aux_df['category'].values, \n",
    "            yticklabels=aux_df['category'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 8, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc_0 =SVC(random_state=8)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "print(svc_0.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_0.fit(features_train, labels_train)\n",
    "svc_pred = svc_0.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.980019652800524\n",
      "The test accuracy is: \n",
      "0.8719851576994434\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, svc_0.predict(features_train)))\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       269\n",
      "           1       0.90      0.84      0.87       270\n",
      "\n",
      "    accuracy                           0.87       539\n",
      "   macro avg       0.87      0.87      0.87       539\n",
      "weighted avg       0.87      0.87      0.87       539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation testing\n",
    "\n",
    "Above we have done hold out testing and below we will perform Cross validation testing to test the performance of our model.\n",
    "As expected cross validation testing gave better results, as in cv testing the model gets a chance to train on comparatively more data which helps it to learn more classification pattern.\n",
    "<br>\n",
    "<br>\n",
    "We have used pipepline to carry out cross-validation testing. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.914251510925151"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    " ('vec', CountVectorizer(stop_words=\"english\")),\n",
    " ('tfidf', TfidfTransformer(use_idf=True)),\n",
    " ('clf', SVC())\n",
    "])\n",
    "\n",
    "#y = BFdf['category'].map({'Books': 1, 'Film': 0}).astype(int)\n",
    "acc_scores = cross_val_score(pipeline2, BFdf['document'], BFdf['Category_Code'], cv=15, scoring=\"accuracy\")\n",
    "\n",
    "acc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we just want documents to be correctly predicted. The costs of false positives or false negatives are the same to us. So, it does not matter whether our classifier is more specific or more sensitive, as long as it classifies correctly as much documents as possible. Therefore, we will consider the accuracy when comparing models.\n",
    "\n",
    "#### From the above test results we will choose SVM for further predictions as it gave the highest accuracy score compared to KNN and MultinomialNB\n",
    "\n",
    "We will now create binary classifier models for the remaining 2 pairs of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test splits for Book and Music category.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(BMdf['document'], \n",
    "                                                    BMdf['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3075, 300)\n",
      "(543, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 8, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "svc_0 =SVC(random_state=8)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "print(svc_0.get_params())\n",
    "svc_0.fit(features_train, labels_train)\n",
    "svc_pred = svc_0.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.9785365853658536\n",
      "The test accuracy is: \n",
      "0.8784530386740331\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, svc_0.predict(features_train)))\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       266\n",
      "           1       0.88      0.88      0.88       277\n",
      "\n",
      "    accuracy                           0.88       543\n",
      "   macro avg       0.88      0.88      0.88       543\n",
      "weighted avg       0.88      0.88      0.88       543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9286798578009443"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    " ('vec', CountVectorizer(stop_words=\"english\")),\n",
    " ('tfidf', TfidfTransformer(use_idf=True)),\n",
    " ('clf', SVC())\n",
    "])\n",
    "\n",
    "y = BMdf['category'].map({'Books': 1, 'Music': 0}).astype(int)\n",
    "acc_scores = cross_val_score(pipeline2, BMdf['document'], y, cv=15, scoring=\"accuracy\")\n",
    "\n",
    "acc_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test splits for Book and Film category.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(MFdf['document'], \n",
    "                                                    MFdf['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3032, 300)\n",
      "(536, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_0.fit(features_train, labels_train)\n",
    "svc_pred = svc_0.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.9812005277044855\n",
      "The test accuracy is: \n",
      "0.8656716417910447\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, svc_0.predict(features_train)))\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       298\n",
      "           1       0.85      0.84      0.85       238\n",
      "\n",
      "    accuracy                           0.87       536\n",
      "   macro avg       0.86      0.86      0.86       536\n",
      "weighted avg       0.87      0.87      0.87       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report of Music and Film binary classifier\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9316101123993903"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    " ('vec', CountVectorizer(stop_words=\"english\")),\n",
    " ('tfidf', TfidfTransformer(use_idf=True)),\n",
    " ('clf', SVC())\n",
    "])\n",
    "\n",
    "y = MFdf['category'].map({'Music': 1, 'Film': 0}).astype(int)\n",
    "acc_scores = cross_val_score(pipeline2, MFdf['document'], y, cv=15, scoring=\"accuracy\")\n",
    "\n",
    "acc_scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above scenarios we can see that cross validation testing has always given better accuracy compared to hold out testing.\n",
    "\n",
    "### Task 3. Multi-class Text Classification\n",
    "\n",
    "Some binary classifiers do not support multi-class classification. For SVM to be used for multi-class classification we need to set an input parameter \"decision_function_shape\" to 'ovo'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [document, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Created a dataframe for Multiclass text classification\n",
    "MCcolumns = [\"document\",\"category\"]\n",
    "MCdf = pd.DataFrame(columns=MCcolumns)\n",
    "MCdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honest youre  go  read   book   holiday  eve...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mariah careys twitter account hack  new years...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>providence lose  paul lay review –  rise  fal...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>war epics airmen  young sopranos essential fi...</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im   hunt  humour  hope   author  read  2020m...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>banging toons  band   bis  make soundtracks  ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>little scratch  rebecca watson review -  dari...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>matter  survival  songs  get us  2020isaac ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>‘ take  toll’  terrible legacy  martin luther...</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>mf doom iconic mask hip-hop mc die age 49mf d...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document category\n",
       "0       honest youre  go  read   book   holiday  eve...    Books\n",
       "1      mariah careys twitter account hack  new years...    Music\n",
       "2      providence lose  paul lay review –  rise  fal...    Books\n",
       "3      war epics airmen  young sopranos essential fi...     Film\n",
       "4      im   hunt  humour  hope   author  read  2020m...    Books\n",
       "...                                                 ...      ...\n",
       "5384   banging toons  band   bis  make soundtracks  ...    Music\n",
       "5385   little scratch  rebecca watson review -  dari...    Books\n",
       "5386     matter  survival  songs  get us  2020isaac ...    Music\n",
       "5387   ‘ take  toll’  terrible legacy  martin luther...     Film\n",
       "5388   mf doom iconic mask hip-hop mc die age 49mf d...    Music\n",
       "\n",
       "[5389 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Added rows belonging to all categories to the dataframe\n",
    "r = 0\n",
    "for index, row in df.iterrows():\n",
    "    MCdf.loc[r] = [row['title'] + row['snippet'] , row['category']]\n",
    "    r += 1\n",
    "MCdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'Books': 0,\n",
    "    'Music': 1,\n",
    "    'Film': 2\n",
    "}\n",
    "# Category mapping\n",
    "MCdf['Category_Code'] = MCdf['category']\n",
    "MCdf = MCdf.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test splits for Book and Music category.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(MCdf['document'], \n",
    "                                                    MCdf['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4580, 300)\n",
      "(809, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_0 =SVC(random_state=8,decision_function_shape='ovo')\n",
    "\n",
    "svc_0.fit(features_train, labels_train)\n",
    "svc_pred = svc_0.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.9543668122270742\n",
      "The test accuracy is: \n",
      "0.7911001236093943\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, svc_0.predict(features_train)))\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       276\n",
      "           1       0.78      0.81      0.79       257\n",
      "           2       0.87      0.75      0.80       276\n",
      "\n",
      "    accuracy                           0.79       809\n",
      "   macro avg       0.80      0.79      0.79       809\n",
      "weighted avg       0.80      0.79      0.79       809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report of Music and Film binary classifier\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734426867733672"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we increase the number of folds i.e. the value of cv the accuracy of the model also increases.\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    " ('vec', CountVectorizer(stop_words=\"english\")),\n",
    " ('tfidf', TfidfTransformer(use_idf=True)),\n",
    " ('clf', SVC(decision_function_shape='ovo'))\n",
    "])\n",
    "\n",
    "acc_scores = cross_val_score(pipeline2, MCdf['document'], MCdf['category'], cv=5, scoring=\"accuracy\")\n",
    "\n",
    "acc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class vs Binary class classifier results evaluation\n",
    "The greater the number of output nodes the higher complexity of our model. This means that given a fixed amount of data, a greater number of output nodes will lead to poorer results. Hence, the accuracy score of our multi-class classifier is less than that of the binary classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We began by exploring the simplest form of classification - binary. This helped us to model data where our response could take one of two states.\n",
    "\n",
    "We then moved further into multi-class classification, when the response variable can take more than 2 states. Here we have 3 states.\n",
    "\n",
    "Then we fit and evaluate models with training and test sets. Furthermore, we can explore additional ways to refine model fitting among various algorithms by changing their input parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
